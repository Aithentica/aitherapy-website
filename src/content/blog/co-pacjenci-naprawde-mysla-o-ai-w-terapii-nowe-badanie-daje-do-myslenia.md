---
title: "Co pacjenci naprawdę myślą o AI w terapii? Nowe badanie daje do myślenia."
description: "Nowy systematyczny przegląd badań pokazuje, jak pacjenci doświadczają narzędzi AI w terapii poznawczo-behawioralnej. Sześć kluczowych tematów — od korzyści po obawy o prywatność — daje do myślenia każdemu, kto projektuje lub używa cyfrowych narzędzi terapeutycznych."
pubDate: 2025-12-31
author: "Bartlomiej Glowacki"
category: "Artykuły Naukowe"
tags: ["AI", "Badania", "CBT", "EtykaAI"]
draft: false
heroImage: "/images/blog/co-pacjenci-naprawde-mysla.jpg"
---

Kiedy budujemy Therapy Support™, często myślimy z perspektywy terapeuty. Bo to terapeuta jest w centrum naszego systemu — to on podejmuje decyzje kliniczne, to on buduje relację, to on odpowiada za proces.

Ale jest jeszcze druga strona tej relacji. Pacjent.

I właśnie ukazało się badanie, które systematycznie zbiera głosy pacjentów korzystających z narzędzi AI wspierających terapię poznawczo-behawioralną. Warto się nad nim pochylić — nie po to, żeby wyciągać pochopne wnioski, ale żeby lepiej rozumieć, z czym mierzą się osoby po drugiej stronie ekranu.

## O jakim badaniu mówimy?

W grudniu 2025 roku w Journal of Mental Health opublikowano systematyczny przegląd badań jakościowych pt. _„Patient perspectives on AI-powered cognitive behavioral therapy tools in managing anxiety and stress"_ (Shankar i wsp., 2025).

Autorzy przeszukali osiem baz danych i przeanalizowali dziewięć badań z dziewięciu różnych krajów, obejmujących ponad 600 uczestników. Ich celem było zrozumienie, jak pacjenci doświadczają narzędzi AI w kontekście radzenia sobie z lękiem i stresem.

To nie jest kolejne badanie skuteczności. To badanie o doświadczeniach — o tym, co ludzie czują, myślą i czego potrzebują, gdy korzystają z cyfrowych narzędzi terapeutycznych.

## Sześć tematów, które wyłoniły się z analizy

Autorzy zidentyfikowali sześć głównych obszarów tematycznych:

**1\. Postrzegane korzyści i wartość terapeutyczna** Pacjenci doceniają zwiększoną samoświadomość, którą dają im narzędzia AI. Cenią też dostępność 24/7 — możliwość sięgnięcia po wsparcie wtedy, gdy tego potrzebują, a nie tylko w godzinach pracy gabinetu.

**2\. Ograniczenia techniczne i wyzwania personalizacji** Narzędzia AI wciąż mają trudności z dostosowaniem się do indywidualnych potrzeb. Pacjenci zauważają, że odpowiedzi bywają zbyt ogólne, a interakcje — sztywne.

**3\. Zaufanie, prywatność i akceptowalność** To obszar, który szczególnie nas interesuje. Pacjenci chcą wiedzieć, co dzieje się z ich danymi. Chcą mieć kontrolę. Chcą rozumieć, jak system działa.

**4\. Preferencje dotyczące interfejsów konwersacyjnych i integracji z człowiekiem** Tu pojawia się kluczowy wniosek: pacjenci konsekwentnie postrzegają narzędzia AI jako uzupełnienie ludzkiej terapii — nie jako jej zamiennik. Chcą, żeby AI wspierało proces, ale nie chcą, żeby zastępowało terapeutę.

**5\. Czynniki ułatwiające i utrudniające zaangażowanie** Łatwość użycia, szybkość reakcji, poczucie bycia wysłuchanym — to zwiększa zaangażowanie. Techniczne problemy, brak responsywności, wrażenie „rozmowy ze ścianą" — to je zmniejsza.

**6\. Wpływy kulturowe i demograficzne** Doświadczenia pacjentów różnią się w zależności od kontekstu kulturowego i demograficznego. To przypomnienie, że nie ma jednego uniwersalnego rozwiązania.

## Co to oznacza dla nas — i dla Was?

Jako zespół Therapy Support™ czytamy to badanie z dużą uwagą. Nie dlatego, że dostarcza nam gotowych odpowiedzi — ale dlatego, że zadaje właściwe pytania.

Kilka refleksji, które się nasuwają:

**Po pierwsze: przejrzystość ma znaczenie.** Pacjenci chcą wiedzieć, jak działa system. Chcą rozumieć, skąd pochodzą sugestie. W naszym podejściu od początku stawiamy na filozofię „cytat-dowód" — każda propozycja AI ma wskazanie źródła w notatkach. To nie jest tylko techniczny wymóg. To budowanie zaufania.

**Po drugie: AI jako wsparcie, nie zamiennik.** Badanie potwierdza to, co powtarzamy od początku: prawdziwa relacja terapeutyczna jest niezastępowalna. AI może porządkować, przypominać, strukturyzować — ale nie może zastąpić obecności drugiego człowieka. I nie powinno próbować.

**Po trzecie: personalizacja to wciąż wyzwanie.** Pacjenci zauważają, gdy system jest zbyt ogólny. To dla nas przypomnienie, że każdy przypadek jest inny i że dobry system musi to uwzględniać — nie przez „sztuczną empatię", ale przez rzetelne porządkowanie indywidualnego materiału klinicznego.

## Zamiast podsumowania — pytanie

Nie wiemy jeszcze, jak te wnioski przełożą się na praktykę. Badanie ma swoje ograniczenia — autorzy sami wskazują na ograniczenie do publikacji anglojęzycznych i heterogeniczność analizowanych interwencji.

Ale jedno wydaje się pewne: głos pacjenta w dyskusji o AI w psychoterapii jest niezbędny. Nie możemy budować narzędzi „dla pacjentów" bez słuchania pacjentów.

I może właśnie to jest najważniejsza lekcja z tego badania: że technologia — nawet najlepsza — ma sens tylko wtedy, gdy służy ludziom. Obu stronom relacji terapeutycznej.

* * *

**Źródło:** Shankar R., Foo T.H., Devi F., Xu Q. (2025). Patient perspectives on AI-powered cognitive behavioral therapy tools in managing anxiety and stress: a systematic review of qualitative studies. _Journal of Mental Health_. Published online: 5 December 2025. DOI: 10.1080/09638237.2025.2595612
